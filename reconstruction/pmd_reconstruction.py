import os, sys, glob
import numpy as np
import cv2
from cv2 import aruco
import matplotlib
import matplotlib.pyplot as plt
from reconstruction.pmd_unwrap import *

def PhaseMeasuringDeflectometry(addImgPath, metric_factor, cameraMatrix, disCoeffs, ret, rc2s, tc2s, half_length, half_height, marker_size, resolution, obj_folder, img_pattern):
    files = glob.glob(os.path.join(obj_folder, 'period_*'))
    files.sort(key = lambda x: int(x.split('_')[-1]))
    normalPath = os.path.join(files[-1], 'normal_result/')
    rawImgPath = os.path.join(files[-1], 'undistort/')

    if not os.path.exists(normalPath):
        os.makedirs(normalPath)

    imgFile = addImgPath
    imgUndistortFile = os.path.join(rawImgPath, "capture_0" + img_pattern.split('*')[1])
    #path of output normal map
    normalFile = os.path.join(normalPath, "normal_map.png")
    
    rcamera_dis = rc2s
    tcamera_dis = tc2s
    # additional section: Make sure that the shape of rC2S and tC2S is correct
    tcamera_dis = np.reshape(tcamera_dis, (3,))
    
    PhaseMap0, PhaseMap1 = phase_unwrap(obj_folder, img_pattern) # unwrap phase maps generated by 4-phase shift algorithm
    PhaseMapHC, PhaseMapVC = screen_phase_unwrap(resolution, obj_folder) # unwrap screen projected phase maps

    # depending on where the camera/screen is located, direction converting is required
    # PhaseMapVC = PhaseMapVC[::-1]
    PhaseMapHC = PhaseMapHC[::-1] # this one only enabled

    # phase plot
    fig, ax = plt.subplots(1, 2, figsize=(15,6))
    p0 = ax[0].imshow(PhaseMap0, cmap='gray')
    fig.colorbar(p0, ax=ax[0])
    ax[0].axis('off')
    ax[0].set_title('Horizontal Phase Unwrap')
    p1 = ax[1].imshow(PhaseMap1, cmap='gray')
    fig.colorbar(p1, ax=ax[1])
    ax[1].axis('off')
    ax[1].set_title('Vertical Phase Unwrap')
    fig.tight_layout()
    fig.savefig(normalPath + '/phase_unwrap' + '.png')
    plt.show()

    # PhaseMap0 = np.unwrap(PhaseMap0, axis=1)
    # PhaseMap1 = np.unwrap(PhaseMap1, axis=0)

    #define board (plane of the object), then estimate the pose of that board using the markers on the object
    allCorners = []
    allIds = []
    dictionary = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_4X4_250)
    img = cv2.imread(imgFile)
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    [markerCorners, markerIDs, rejectedImgPoints] = cv2.aruco.detectMarkers(gray, dictionary, cameraMatrix=cameraMatrix, distCoeff=disCoeffs)


    board_corner = np.array([np.array([[-half_length, -half_height, 0], [-half_length + marker_size, -half_height, 0], [-half_length + marker_size, -half_height + marker_size, 0], [-half_length, -half_height + marker_size, 0]]),
                    np.array([[half_length - marker_size, -half_height, 0], [half_length, -half_height, 0], [half_length, -half_height + marker_size, 0], [half_length - marker_size, -half_height + marker_size, 0]]),
                    np.array([[half_length - marker_size, half_height - marker_size, 0], [half_length, half_height - marker_size, 0], [half_length, half_height, 0], [half_length - marker_size, half_height, 0]]),
                    np.array([[-half_length, half_height - marker_size, 0], [-half_length + marker_size, half_height - marker_size, 0], [-half_length + marker_size, half_height, 0], [-half_length, half_height, 0]]),
                    np.array([[-marker_size/2, -half_height, 0], [marker_size/2, -half_height, 0], [marker_size/2, -half_height + marker_size, 0], [-marker_size/2, -half_height + marker_size, 0]]),
                    np.array([[-half_length, -marker_size/2, 0], [-half_length + marker_size, -marker_size/2, 0], [-half_length + marker_size, marker_size/2, 0], [-half_length, marker_size/2, 0]]),
                    np.array([[half_length - marker_size, -marker_size/2, 0], [half_length, -marker_size/2, 0], [half_length, marker_size/2, 0], [half_length - marker_size, marker_size/2, 0]])], dtype=np.float32)

    board_id = np.array([[0], [6], [4], [2], [7], [1], [5]], dtype=np.int32)
    board = cv2.aruco.Board_create(board_corner, dictionary, board_id)

    if len(markerCorners) > 0:
        allCorners.append(markerCorners)
        allIds.append(markerIDs)
        cv2.aruco.drawDetectedMarkers(img, markerCorners, markerIDs, [0,200,0])


    rvecs,tvecs,_objpoints = cv2.aruco.estimatePoseSingleMarkers(markerCorners, marker_size, cameraMatrix, disCoeffs, )
    print(rvecs)
    r_mean = np.mean(rvecs,axis=0)
    t_mean = np.mean(tvecs,axis=0)
    r_mirror = None
    t_mirror = None
    ret, r_mirror, t_mirror, = cv2.aruco.estimatePoseBoard(markerCorners, markerIDs, board, cameraMatrix, disCoeffs, r_mirror, t_mirror)
    r_mirror_mat = np.zeros((3,3))
    r_mirror_mat = cv2.Rodrigues(r_mirror,dst= r_mirror_mat,jacobian=None)
    r_mirror_mat = r_mirror_mat[0]
    #print("r mirror mat is ", r_mirror_mat)
    img_axis = aruco.drawAxis(img, cameraMatrix, disCoeffs, r_mirror, t_mirror, marker_size)
    width = 960
    height = int(img.shape[0]*960/img.shape[1])
    smallimg = cv2.resize(img,(width,height))
    smallimg = cv2.cvtColor(smallimg, cv2.COLOR_BGR2RGB)
    plt.figure(figsize=(8,6))
    plt.imshow(smallimg)
    plt.show()

    #rtcam: camera coordinate system to world coordinate system
    #rtMat: world coordinate system to camera coordinate system
    rtMat = np.hstack((r_mirror_mat, t_mirror))
    rtMat = np.vstack((rtMat, np.array([[0, 0, 0, 1]])))
    rt_cam = np.linalg.inv(rtMat)
    r_cam = rt_cam[0:3, 0:3]
    t_cam = rt_cam[0:3, 3]
    #print("rtMat is",rtMat)
    #print("rtcam in world coor is ", rt_cam)

    #rtdis: display coordinate system to world coordinate system
    #rtdis_inv: world coordinate system to display coordinate system
    t_camdis = np.reshape(tcamera_dis, (tcamera_dis.shape[0],1))
    rtMat_camdis = np.hstack((rcamera_dis, t_camdis))
    rtMat_camdis = np.vstack((rtMat_camdis, np.array([0,0,0,1])))
    rt_dis_inv = np.matmul(rtMat_camdis, rtMat)
    rt_dis = np.linalg.inv(rt_dis_inv)
    r_dis = rt_dis[0:3, 0:3]
    t_dis = rt_dis[0:3,3]
    r_dis_inv = rt_dis_inv[0:3,0:3]
    t_dis_inv = rt_dis_inv[0:3,3]
    #print("rtscreen in world coor is ", rt_dis)
    #print("mirror in screen coor is ",rt_dis_inv)

    #load undistorted image
    img_undistort = cv2.imread(imgUndistortFile)
    gray_undistort = cv2.cvtColor(img_undistort, cv2.COLOR_BGR2GRAY)
    img_undistort_size = gray_undistort.shape

    # reshape t vector
    t_cam = np.reshape(t_cam, (t_cam.shape[0], 1))
    t_dis = np.reshape(t_dis, (t_dis.shape[0], 1))
    t_dis_inv = np.reshape(t_dis_inv, (t_dis_inv.shape[0], 1))

    #cam coor mat:store vectors in camera coordinate system
    #cam world coor mat: store vectors in world coordinate system
    #camera mirror intersect mat: store intersect points between arrival vectors and mirror in world coordinate system
    # display intersect mat: store display intersect points on display coordinate system
    # display intersect mat trans: store display intersect points on world coordinate system
    # reflec mat: store reflectance vectors in world coordinate system 
    # normal mat: store normalized normal vectors in world coordinate system
    # normal mat trans: store normalized normal vectors in camera coordinate system
    # normal mat origin: store mormalized normal vectors in world coordinate system
    img_coor_mat = np.zeros((3, img_undistort_size[0], img_undistort_size[1]))
    cam_coor_mat = np.zeros((3, img_undistort_size[0], img_undistort_size[1]))
    img_coor_mat_rs = np.zeros((3, img_undistort_size[0]*img_undistort_size[1]))
    cam_coor_mat_rs = np.zeros((3, img_undistort_size[0]*img_undistort_size[1]))
    cam_world_coor_mat = np.zeros((3, img_undistort_size[0]*img_undistort_size[1]))
    cam_mirror_intersect_mat = np.zeros((3, img_undistort_size[0]*img_undistort_size[1]))
    reflect_mat = np.zeros((3, img_undistort_size[0]*img_undistort_size[1]))
    display_intersect_mat = np.zeros((3, img_undistort_size[0]*img_undistort_size[1]))
    display_intersect_mat_trans = np.zeros((3, img_undistort_size[0]*img_undistort_size[1]))
    normal_mat = np.zeros((3, img_undistort_size[0]*img_undistort_size[1]))
    normal_mat_trans = np.zeros((3, img_undistort_size[0]*img_undistort_size[1]))
    normal_mat_origin = np.zeros((3, img_undistort_size[0]*img_undistort_size[1]))
    #calculate normal vectors 
    for i in range(img_undistort_size[0]):
        for j in range(img_undistort_size[1]):
            image_coor = np.array([j + 1, i + 1, 1])
            img_coor_mat[:,i,j] = image_coor

    img_coor_mat_rs = np.reshape(img_coor_mat, (3, img_undistort_size[0]*img_undistort_size[1]))
    # calculate arrival vector
    cam_coor_mat_rs = np.matmul(np.linalg.inv(cameraMatrix), img_coor_mat_rs)
    cam_world_coor_mat = np.matmul(r_cam, cam_coor_mat_rs)
    # calculate intersect point
    scale_factor1 = -t_cam[2,0] / cam_world_coor_mat[2,:]
    scale_factor1 = np.reshape(scale_factor1, (1, scale_factor1.shape[0]))
    cam_mirror_intersect_mat = scale_factor1 * cam_world_coor_mat + np.tile(t_cam, (cam_world_coor_mat.shape[1]))
    # reshape phase map (for phase value calculation)
    PhaseMap0_rs = np.reshape(PhaseMap0, (img_undistort_size[0]*img_undistort_size[1],))
    PhaseMap1_rs = np.reshape(PhaseMap1, (img_undistort_size[0]*img_undistort_size[1],))

    # find corresponding position on screen using phase value
    for i in range(img_undistort_size[0]*img_undistort_size[1]):
        phasevalueH = PhaseMap0_rs[i]
        phasevalueV = PhaseMap1_rs[i]
        phasediffH = np.abs(PhaseMapHC - phasevalueH)
        phasediffV = np.abs(PhaseMapVC - phasevalueV)
        h_index = np.argmin(phasediffH)
        v_index = np.argmin(phasediffV)
        h_loc = h_index - img_undistort_size[1]/2
        v_loc = v_index - img_undistort_size[0]/2
        h_loc_metric = h_loc * metric_factor
        v_loc_metric = v_loc * metric_factor
        # x axis adjustment
        h_loc_metric = -h_loc_metric
        display_intersect_point = np.array([h_loc_metric, v_loc_metric, 0])
        display_intersect_mat[:,i] = display_intersect_point

    # calculate arrival and reflectance fector
    display_intersect_mat_trans = np.dot(r_dis, display_intersect_mat) + np.tile(t_dis, (cam_world_coor_mat.shape[1]))
    reflect_mat = display_intersect_mat_trans - cam_mirror_intersect_mat
    arrival_vec_norm = -cam_world_coor_mat
    arrival_vec_norm = arrival_vec_norm / np.linalg.norm(arrival_vec_norm, axis= 0)
    reflect_vec_norm = reflect_mat / np.linalg.norm(reflect_mat, axis= 0)
    # use normalized arrival and reflectance vector to calculate normal fectors, then normalize normal vectors
    normal_mat = arrival_vec_norm + reflect_vec_norm
    normal_mat_origin = normal_mat / np.linalg.norm(normal_mat, axis= 0)
    normal_mat_trans = np.array([normal_mat_origin[1,:], -normal_mat_origin[0,:], -normal_mat_origin[2,:]])

    # restore the shape of matrix and normal vector matrix
    cam_mirror_intersect_mat = np.reshape(cam_mirror_intersect_mat, (3, img_undistort_size[0], img_undistort_size[1]))
    normal_mat_origin = np.reshape(normal_mat_origin, (3, img_undistort_size[0], img_undistort_size[1]))
    normal_mat_trans = np.reshape(normal_mat_trans, (3, img_undistort_size[0], img_undistort_size[1]))
    # the original matrix is (3, 1200, 1900) and we need to transfer it to (1200, 1920, 3) in order to be compatable to normal export codes
    cam_mirror_intersect_rs = np.zeros((img_undistort_size[0], img_undistort_size[1], 3))
    normal_mat_origin_rs = np.zeros((img_undistort_size[0], img_undistort_size[1], 3))
    normal_mat_trans_rs = np.zeros((img_undistort_size[0], img_undistort_size[1], 3))
    for i in range(normal_mat_trans.shape[0]):
        cam_mirror_intersect_rs[:,:,i] = cam_mirror_intersect_mat[i,:,:]
        # Use variance data to filter the invalid normal data (caused by diffused surface)
        if i == 2:
            normal_mat_origin_rs[:,:,i] = normal_mat_origin[i,:,:] 
            normal_mat_trans_rs[:,:,i] = normal_mat_trans[i,:,:] 
        else:
            normal_mat_origin_rs[:,:,i] = normal_mat_origin[i,:,:] 
            # try to magnify x and y elements
            normal_mat_trans_rs[:,:,i] = normal_mat_trans[i,:,:] 

    cam_mirror_intersect_mat = cam_mirror_intersect_rs
    normal_mat_origin = normal_mat_origin_rs
    normal_mat_trans = normal_mat_trans_rs

    #encode the normal vectors into the RGB image
    #np.savez(os.path.join(rootImgPath, "results/intersect_world"),cam_mirror_intersect_mat)
    np.savez(os.path.join(normalPath, "normal_map"), normal_mat_origin)
    #np.savez(os.path.join(rootImgPath, "results/normal_map_trans"), normal_mat_trans)
    normal_img = cv2.cvtColor(np.array((normal_mat_trans + 1) / 2.0 * 255, dtype= np.uint8), cv2.COLOR_RGB2BGR)
    cv2.imwrite(normalFile, normal_img)
    print("normal map generated.")

    # this part transfer the normal map from camera coordiante into world coordinate
    normalmap_world = normalInWorld(cam_mirror_intersect_mat= cam_mirror_intersect_mat, normal_map= normal_mat_origin, half_length= half_length, half_height = half_height)
    return normal_mat_trans, normal_mat_origin, normalmap_world

def normal_rgb_to_curvature(normal_rgb, normal_path):
    # central difference kernel with a shift of 0.5 in both x and y directions
    kernel_x = np.array([[-0.5, 0, 0.5],
                        [-0.5, 0, 0.5],
                        [-0.5, 0, 0.5]])
    kernel_y = np.array([[-0.5, -0.5, -0.5],
                        [0, 0, 0],
                        [0.5, 0.5, 0.5]])
    
    # Split the image into its three color channels
    b, g, r = cv2.split(normal_rgb)

    # apply kernels to each channel
    dx_b = cv2.filter2D(b, -1, kernel_x)
    dy_b = cv2.filter2D(b, -1, kernel_y)

    dx_g = cv2.filter2D(g, -1, kernel_x)
    dy_g = cv2.filter2D(g, -1, kernel_y)

    dx_r = cv2.filter2D(r, -1, kernel_x)
    dy_r = cv2.filter2D(r, -1, kernel_y)

    # Merge the gradient channels back into a single color image
    dx = cv2.merge([dx_b, dx_g, dx_r])
    dy = cv2.merge([dy_b, dy_g, dy_r])

    # save image
    cv2.imwrite(os.path.join(normal_path, "curvature_dx.png"), cv2.cvtColor(np.array((dx + 1) / 2.0 * 255, dtype= np.uint8), cv2.COLOR_RGB2BGR))
    cv2.imwrite(os.path.join(normal_path, "curvature_dy.png"), cv2.cvtColor(np.array((dy + 1) / 2.0 * 255, dtype= np.uint8), cv2.COLOR_RGB2BGR))

    # gradient magnitude
    mag_b = cv2.magnitude(dx_b, dy_b)
    mag_g = cv2.magnitude(dx_g, dy_g)
    mag_r = cv2.magnitude(dx_r, dy_r)

    # Combine the magnitude of the gradients for each channel to get the final magnitude for each pixel
    mag = cv2.sqrt(np.square(mag_b) + np.square(mag_g) + np.square(mag_r))
    cv2.imwrite(os.path.join(normal_path, "curvature_magnitude.png"), cv2.cvtColor(np.array((mag + 1) / 2.0 * 255, dtype= np.uint8), cv2.COLOR_RGB2BGR))

    # row, col plot
    x = cv2.sqrt(np.square(dx_b) + np.square(dx_g) + np.square(dx_r))
    y = cv2.sqrt(np.square(dy_b) + np.square(dy_g) + np.square(dy_r))
    fig, axs = plt.subplots(1, 2, figsize=(12,6))
    axs[0].plot(x[x.shape[0] // 2, :])
    axs[1].plot(y[:, y.shape[1] // 2])
    fig.tight_layout() # to avoid axes overlapping
    fig.savefig(os.path.join(normal_path, "curvature_plot.png"))

def normalInWorld(cam_mirror_intersect_mat, normal_map, half_length, half_height):
    SCALE_FACTOR = 1000

    intersect_point = cam_mirror_intersect_mat
    #varMask = np.load(os.path.join(rootImgPath, "results/mask.npz"))
    #varMask = varMask.f.arr_0
    intersect_x = intersect_point[:,:,0]
    intersect_y = intersect_point[:,:,1]
    normal_map_x = normal_map[:,:,0]
    normal_map_y = normal_map[:,:,1]
    normal_map_z = normal_map[:,:,2]

    
    intersect_x = intersect_x + half_length
    intersect_y = intersect_y + half_height
    intersect_x[intersect_x < 0] = 0
    intersect_x[intersect_x > 2 * half_length] = 0
    intersect_y[intersect_y < 0] = 0
    intersect_y[intersect_y > 2 * half_height] = 0

    print(np.max(intersect_x))
    print(np.max(intersect_y))

    #discretize corld intersect point coordinate.
    intersect_x = intersect_x * SCALE_FACTOR
    intersect_y = intersect_y * SCALE_FACTOR
    intersect_x = np.round(intersect_x)
    intersect_y = np.round(intersect_y)


    normal_map_world = np.zeros((int(np.round(2 * half_height * SCALE_FACTOR) + 1), int(np.round(2 * half_length * SCALE_FACTOR) + 1), 3))
    #varMask_world = np.zeros((int(np.round(2 * half_height * SCALE_FACTOR) + 1), int(np.round(2 * half_length * SCALE_FACTOR) + 1)))
    for i in range(intersect_x.shape[0]):
        for j in range(intersect_x.shape[1]):
            normal_map_world[int(intersect_y[i,j]), int(intersect_x[i,j]), 0] = normal_map_x[i,j] 
            normal_map_world[int(intersect_y[i,j]), int(intersect_x[i,j]), 1] = normal_map_y[i,j]
            normal_map_world[int(intersect_y[i,j]), int(intersect_x[i,j]), 2] = normal_map_z[i,j]
            #varMask_world[int(intersect_y[i,j]), int(intersect_x[i,j])] = varMask[i,j]

    # use mask to filter invalid normals
    #ground_truth_x = ground_truth_x * varMask_world
    #ground_truth_y = ground_truth_y * varMask_world
    #ground_truth_z = ground_truth_z * varMask_world + (varMask_world - 1)
    for i in range(normal_map_world.shape[2]):
        if i == 2:
            normal_map_world[:,:,i] = normal_map_world[:,:,i] #* varMask_world + (varMask_world - 1)
        else:
            normal_map_world[:,:,i] = normal_map_world[:,:,i] #* varMask_world

    return normal_map_world

def normal2RGB(normal_mat_origin, normalmap_world, resultFolder):
    normal_cam = np.array((normal_mat_origin + 1) / 2.0 * 255, dtype= np.uint8)
    normal_cam = cv2.cvtColor(normal_cam, cv2.COLOR_RGB2BGR)
    normal_world = np.array((normalmap_world + 1) / 2.0 * 255, dtype= np.uint8)
    normal_world = cv2.cvtColor(normal_world, cv2.COLOR_RGB2BGR)

    # plot normal maps in both coords
    fig, ax = plt.subplots(1, 2, figsize=(15,6))
    ax[0].imshow(normal_cam)
    ax[0].axis('off')
    ax[0].set_title('Normal Map Camera Coord')
    ax[1].imshow(normal_world)
    ax[1].set_title('Normal Map World Coord')
    ax[1].axis('off')
    plt.show()

    # visualize normal map in camera perspective
    norm = matplotlib.colors.Normalize(vmin= -1, vmax = 1)
    norm2 = matplotlib.colors.Normalize(vmin= -1, vmax = 1)

    # visualize normal map in camera perspective
    fig = plt.figure(figsize=(25,10))
    for i in range(3):
        if i == 2:
            plt.subplot(1,3,i+1)
            plt.imshow(normal_mat_origin[:,:,i], norm= norm2)
            plt.title("Camera Z")
            plt.tick_params(labelsize=14)
        else:
            plt.subplot(1,3,i+1)
            plt.imshow(normal_mat_origin[:,:,i], norm= norm)
            if i == 1:
                plt.title("Camera Y")
            else:
                plt.title("Camera X")
            plt.tick_params(labelsize=14)
        cb = plt.colorbar()
        cb.ax.tick_params(labelsize= 14)
    plt.show()
    fig.savefig(resultFolder + '/normal_camera' + '.png')

    # visualize normal map in world perspective
    fig = plt.figure(figsize=(25,10))
    for i in range(3):
        if i == 2:
            plt.subplot(1,3,i+1)
            plt.imshow(normalmap_world[:,:,i], norm= norm2)
            plt.title("World Z")
            plt.tick_params(labelsize=14)
        else:
            plt.subplot(1,3,i+1)
            plt.imshow(normalmap_world[:,:,i], norm= norm)
            if i == 1:
                plt.title("World Y")
            else:
                plt.title("World X")
            plt.tick_params(labelsize=14)
        cb = plt.colorbar()
        cb.ax.tick_params(labelsize= 14)
    plt.show()
    fig.savefig(resultFolder + '/normal_world' + '.png')
        